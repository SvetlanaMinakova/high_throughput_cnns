// File automatically generated by ESPAM
#include "arm_compute/graph.h"
#include "support/ToolchainSupport.h"
#include "utils/CommonGraphOptions.h"
#include "utils/GraphUtils.h"
#include "utils/Utils.h"
#include <chrono>
#include <thread>
#include "Subnet1.h"
#include "fifo.h"
#include "types.h"

using namespace arm_compute::utils;
using namespace arm_compute::graph::frontend;
using namespace arm_compute::graph_utils;

//NETWORK ENGINE WITH API
bool Subnet1::do_setup(int argc, char **argv) {
  
  // Parse arguments
  cmd_parser.parse(argc, argv);
  cmd_parser.validate();
  
  // Consume common parameters
  common_params = consume_common_graph_parameters(common_opts);
  
  // Return when help menu is requested
  if(common_params.help){
    cmd_parser.print_help(argv[0]);
    return false;
 }
 
 // Checks
 ARM_COMPUTE_EXIT_ON_MSG(arm_compute::is_data_type_quantized_asymmetric(common_params.data_type), "QASYMM8 not supported for this graph");
 // Get trainable parameters data path
 std::string data_path = common_params.data_path;
 
 // Set weights trained layout
 const DataLayout weights_layout = DataLayout::NCHW;
 
 //DEFINE INPUT DATA AND START GRAPH
 // Create input_examples tensor
 const TensorShape tensor_shape = permute_shape(TensorShape(this->INPUT_W, this->INPUT_H, this->INPUT_C, 1U), DataLayout::NCHW, common_params.data_layout);
 TensorDescriptor input_descriptor = TensorDescriptor(tensor_shape, common_params.data_type).set_layout(common_params.data_layout);
 
 graph << common_params.target
       << common_params.fast_math_hint
       << InputLayer(input_descriptor, get_input_accessor(common_params, nullptr))
       << ConvolutionLayer(
           5U, 5U, 16U,
           get_weights_accessor(data_path, " ", weights_layout),
           get_weights_accessor(data_path, " "),
           PadStrideInfo(1, 1, 2, 2))
           .set_name("Convolution110")
       << OutputLayer(get_output_accessor(common_params, 5));
 
 
 // Finalize graph
 GraphConfig config;
 
 config.num_threads = common_params.threads;
 config.use_tuner   = common_params.enable_tuner;
 config.tuner_mode  = common_params.tuner_mode;
 config.tuner_file  = common_params.tuner_file;
 
 // Load the precompiled kernels from a file into the kernel library, in this way the next time they are needed
 // compilation won't be required.
 if(common_params.enable_cl_cache) {
   restore_program_cache_from_file();
 }
 
 graph.finalize(common_params.target, config);
 
 // Save the opencl kernels to a file
 if(common_opts.enable_cl_cache) { 
    save_program_cache_to_file();
 }
 
 return true;
 }
 
 // Run graph
 void Subnet1::do_run() { 
   graph.run();
 }
 
