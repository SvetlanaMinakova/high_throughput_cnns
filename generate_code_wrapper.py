import argparse
import traceback
import os
import sys
import json

# Example
# python generate_code_wrapper.py --cnn ./input_examples/dnn/mnist.onnx -p ./input_examples/architecture/jetson.json -a ./input_examples/intermediate/mnist/app.json -o ./output/mnist


def main():
    # import current directory and it's subdirectories into system path for the current console
    # this would allow to import project modules without adding the project to the PYTHONPATH
    this_dir = os.path.dirname(__file__)
    sys.path.append(this_dir)

    # import project modules
    from dnn_builders.input_dnn_manager import load_or_build_dnn_for_analysis
    from models.dnn_model.dnn import set_built_in
    from models.dnn_model.transformation.ops_fusion import fuse_built_in
    from converters.json_converters.json_to_dnn_inf_model import json_to_dnn_inf_model
    from codegen.wrapper.wrapper_dnn_visitor import visit_dnn_app
    from eval.latency.measurements.dnn_inf_app_subnets_latency import get_latency_per_subnet
    from util import print_stage

    # general arguments
    parser = argparse.ArgumentParser(description='The script generates code wrapper, which implements '
                                                 'communication and synchronization primitives but NO '
                                                 'real CNN functionality.')

    parser.add_argument('--cnn', metavar='--cnn', type=str, action='store', required=True,
                        help='path to a CNN. Can be a path to: '
                             '1) a path to an .onnx file; '
                             '2) a path to .h5 file (cnn in format of Keras DL framework). '
                             '3) a path to .json file (cnn in internal format. This format'
                             'can be obtained from on .onnx or .h5 file using ./dnn_to_json script)')

    parser.add_argument('-fo', metavar='--fused-ops', type=str, action='store',
                        default='activation,normalization,arithmetic,skip',
                        help='List built-in (fused) operators within a cnn. A cnn layers, performing a built-in'
                             ' operator is fused with another layer also referred as a "parent" layer. For example'
                             ' an activation (e.g. ReLU) layer, following a convolutional layer,'
                             ' can be fused with the convolutional layer. In this case, the activation layer is'
                             ' the fused layer, and the convolutional layer is the "parent" layer.'
                             ' Fused layers are always mapped onto the same processor'
                             ' as their "parent" layer. Also, fused layers do not have an intermediate'
                             ' output date (output buffer) of their own.'
                             ' NOTE: LIST OF FUSED OPS SHOULD NOT CHANGE BETWEEN THE SUBSEQUENT SCRIPTS')

    parser.add_argument('-a', metavar='--app', type=str, action='store', required=True,
                        help='final DNN inference application, generated by ./generate_final_app_model.py script '
                             'and saved in .json format.')

    parser.add_argument('-o', metavar='--out-dir', type=str, action='store', default="./output",
                        help='path to output files directory')

    parser.add_argument('-e', metavar='--eval-path', type=str, action='store', default=None,
                        help='path to per-layer cnn execution time (latency) evaluation (JSON). '
                             'Use ./sdf_latency_eval_template.py script to generate a template for this file.'
                             'If this file used, execution primitive of every Subnet node in the wrapper code will be '
                             'delayed by respective time, enabling for timed representation of final '
                             'application. Otherwise, the representation is untimed (execution primitive of every '
                             'Subnet node will take ~0 seconds)')

    # general flags
    parser.add_argument("--silent", help="do not provide print-out for the script steps", action="store_true", default=False)

    args = parser.parse_args()
    try:
        # Extract parameters from command-line arguments"
        cnn_path = args.cnn
        app_path = args.a

        eval_path = args.e
        output_dir = args.o
        silent = args.silent
        verbose = not silent
        fused_ops_spec = args.fo
        fused_ops = fused_ops_spec.split(',')

        # read DNN
        stage = "Reading input DNN"
        print_stage(stage, verbose)
        dnn = load_or_build_dnn_for_analysis(cnn_path, verbose=verbose)
        # print DNN
        # dnn.print_details()

        # optimize dnn: fuse operators
        if len(fused_ops) > 0:
            stage = "Optimize DNN: fuse layers that perform operators " + str(fused_ops_spec)
            print_stage(stage, verbose)
            set_built_in(dnn, fused_ops)
            fuse_built_in(dnn)

        stage = "Reading DNN inference model"
        print_stage(stage, verbose)
        dnn_inf_model = json_to_dnn_inf_model(app_path)

        # evaluate execution time of every sub-network (partition)
        time_per_subnet = {}
        if eval_path is not None:
            stage = "Read per-layer execution time (latency) eval table"
            print_stage(stage, verbose)
            time_per_subnet = get_latency_per_subnet(eval_path, dnn_inf_model)

        stage = "Generating wrapper code"
        print_stage(stage, verbose)
        code_folder = output_dir + "/code/wrapper"
        visit_dnn_app(dnn, dnn_inf_model, code_folder, time_per_subnet, verbose=verbose)

    except Exception as e:
        print("Wrapper code generation error: " + str(e))
        traceback.print_tb(e.__traceback__)


if __name__ == "__main__":
    main()

